
134
00:09:15,754 --> 00:09:18,254
این وزن هایی که نسبت میدیم، یک عدد هستن

135
00:09:18,384 --> 00:09:25,384
بعد عدد "فعالسازی" همه عصب های لایه اول رو میگیریم و جمع وزن دارشون رو محاسبه میکنیم

136
00:09:26,831 --> 00:09:32,009
تصور کنید این وزن ها خودشون توی ی جدول قرار گرفتن

137
00:09:32,158 --> 00:09:37,532
رنگ سبز به معنی وزن مثبت و قرمز به معنی وزن منفی هست

138
00:09:37,532 --> 00:09:41,940
و روشنایی اون پیکسل، مشخص کننده قدر مطلق مقدار وزنه

139
00:09:42,091 --> 00:09:49,764
خب اگر همه وزن های مربوط به این پیکسل هارو صفر کنیم غیر از جایی که برامون مهمه

140
00:09:49,759 --> 00:09:58,259
اون موقع برای محاسبه وزن همه پیکسل ها، کافیه که فقط جمع وزن دار اون قسمت رو محاسبه کنیم

141
00:09:58,648 --> 00:10:02,355
و اگر بخوای بفهمی که آیا اون قسمت توی عکس گوشه است یا نه

142
00:10:02,355 --> 00:10:07,355
راه حلش اینه که ی سری وزن منفی دور اون قسمت داشته باشی

143
00:10:07,389 --> 00:10:13,807
وقتی جمع مثبت میشه که اون پیکسل های وسط روشن تر باشن و پیکسل های دورش تیره تر

144
00:10:14,541 --> 00:10:18,951
اگر با این روش وزن رو حساب کنی، ممکنه هر عددی بدست بیاری

145
00:10:18,980 --> 00:10:24,094
ولی برای این شبکه، ما میخوایم که عدد فعالسازی هر عصب ی چیزی بین 0 و 1 باشه

146
00:10:24,094 --> 00:10:31,855
ی روش رایج اینه که عددمون رو بدیم به ی تابع که بازه اعداد حقیقی رو به ی چیزی بین 0 و 1 تبدیل کنه

147
00:10:32,517 --> 00:10:35,662
ی تابع معروف که اینکارو میکنه، تابع "سیگموید" هستش

148
00:10:35,677 --> 00:10:37,690
که بهش "شیب منطقی" هم میگن

149
00:10:37,783 --> 00:10:43,634
به طور ساده اینطوری که خروجی ی عدد خیلی منفی، نزدیک 0 و ی خروجی ی عدد خیلی مثبت نزدیک 1 میشه

150
00:10:43,875 --> 00:10:46,941
و اطراف عدد 0 با مقدارش زیاد میشه

151
00:10:48,899 --> 00:10:56,595
پس عدد فعالسازی یک عصب، یک اندازه گیری هست که مشخص میکنه جمع وزن متناظرش چقدره

152
00:10:57,144 --> 00:11:01,964
ولی شاید تو نخوای وقتی که جمع مثبت بشه، این عصب فعال بشه

153
00:11:01,964 --> 00:11:06,768
شاید توی میخوای وقتی این عصب فعال بشه که مقدارش بیشتر از 10 بشه

154
00:11:06,879 --> 00:11:10,899
یعنی تو به ی مبنا احتیاج داری که مرز بین فعال شدن و نشدن رو مشخص کنه

155
00:11:10,899 --> 00:11:19,899
راه حلش اینه که قبل از این که حاصل رو توی تابع سیگموید بزاری، ی عدد به اون حاصل اضافه کنی، به طور مثال -10

156
00:11:20,504 --> 00:11:23,330
به این عدد، میگن مبنا

157
00:11:23,504 --> 00:11:28,687
پس وزن ها مشخص میکنن که چه الگوی پیکسلی رو توی لایه دوم دنبالشی

158
00:11:28,687 --> 00:11:35,187
و عدد مبنا مشخص میکنه که حاصل جمع باید حداقل چند باشه تا اون عصب فعال بشه

159
00:11:35,423 --> 00:11:37,860
این فقط واسه ی عصب بود

160
00:11:37,860 --> 00:11:45,182
همه عصب ها توی لایه دوم هم با همه 784 تا عصب از لایه اول اتصال دارن

161
00:11:45,182 --> 00:11:51,000
و هر کدوم از اون 784 تا اتصال، عددی به عنوان وزن دارن

162
00:11:51,451 --> 00:11:53,634
و هرکدوم عدد مبنا دارن

163
00:11:53,634 --> 00:11:57,849
ی عددی که قبل از این که جمع وزن دار رو به تابع سیگموید بدی، بهش اضافه میکنی

164
00:11:58,238 --> 00:11:59,634
اگر بهش فکر کنی میفهمی که خیلی زیاده!

165
00:11:59,985 --> 00:12:02,466
و با در نظر گرفتن این که لایه دوم 16 تا عصب داره

166
00:12:02,466 --> 00:12:08,311
ا 784*16 تا وزن و عدد مبنا وجود داره

167
00:12:08,311 --> 00:12:12,267
همه اینا تازه اتصال بین لایه اول و دوم بود

168
00:12:12,437 --> 00:12:17,614
اتصال های بین لایه های دیگه هم وزن و عدد مبنا دارن

169
00:12:18,033 --> 00:12:24,086
همه شون رو که حساب کنی، میبینی که 13002 تا ورن و عدد مبنا داره

170
00:12:24,086 --> 00:12:30,113
سیزده هزار متغیر که میشه تغییرشون داد تا این شبکه جور دیگه ای رفتار کنه

171
00:12:30,812 --> 00:12:41,812
پس وقتی میگیم "یادگیری"، منظورمون اینه که با کامپیوتر واسه این همه متغیر، ی سری عدد پیدا کنیم که بتونه مسئله رو حل کنه

172
00:12:42,196 --> 00:12:50,110
توی ی آزمایش ذهنی که به نظرم خیلی وحشتناکه، تصور کن که بشینی و همه این 13 هزار تا متغیر رو دستی تنظیم کنی

173
00:12:50,355 --> 00:12:54,177
جوری دستی این متغیر هارو دستکاری که کنی لایه دوم گوشه هارو پیدا کنه

174
00:12:54,177 --> 00:12:56,677
لایه سوم الگو هارو پیدا کنه و غیره

175
00:12:56,869 --> 00:13:02,369
به نظرم اینطوری بهتره نسبت به موقعی که به شبکه عصبی به صورت ی جعبه سیاه و جادویی نگاه کنی

176
00:13:02,475 --> 00:13:05,423
بخاطر اینکه وقتی شبکه طوری که تو پیشبینی کردی عمل نمیکنه

177
00:13:05,423 --> 00:13:09,883
اگر فهمیدی که هرکدوم از این وزن ها و اعداد مبنا چه معنی میدن

178
00:13:10,120 --> 00:13:14,581
نقطه شروع خوبی میتونه باشه برای اینکه ساختار شبکه رو طوری تغییر بدی تا اوضاع بهتر بشه

179
00:13:14,581 --> 00:13:18,163
یا وقتی که شبکه کار میکنه ولی نه به دلایلی که انتظارشو داشتی

180
00:13:18,163 --> 00:13:22,884
فهمیدن این که این عدد های پایه و وزن ها دارن چیکار میکنن، روش خوبیه تا فرض هایی که داشتی رو به چالش بکشی

181
00:13:22,884 --> 00:13:25,980
و به راه حل های مختلف پی ببری

182
00:13:25,980 --> 00:13:30,980
نوشتن کل این تابع یکم سخته، مگه نه؟

183
00:13:32,071 --> 00:13:37,460
خب بزارید ی روش جمع و جور بهتون نشون بدم که این اتصال هارو نمایش میده

184
00:13:37,567 --> 00:13:40,576
اگر در مورد شبکه عصبی مقاله بخونی، احتمالا فرمول هارو اینطوری میبینی

185
00:13:41,215 --> 00:13:46,245
اینطوری که همه عدد های "فعالسازی" یک لایه رو به صورت ی بردار بنویسی

186
00:13:47,692 --> 00:13:50,570
و همه وزن هارو به صورت ماتریس بنویسی

187
00:13:50,570 --> 00:13:58,181
که هر سطر این ماتریس مشخص کننده وزن های اتصال های بین یک "لایه" و یک "عصب" خاص از لایه بعدی هستن

188
00:13:58,181 --> 00:14:13,181
یعنی جواب جمع وزن دار لایه اول با توجه به هرکدوم از وزن های اتصال ها، میشه عدد توی سطر متناظر ماتریس حاصل

189
00:14:14,365 --> 00:14:18,365
خیلی از مباحث یادگیری ماشین به دونستن جبر خطی وابسته است

190
00:14:18,692 --> 00:14:24,192
برای کسایی که میخوان ی فهم تصویری از این که ماتریس ها چی هستن و ضرب ماتریسی چیه، داشته باشن

191
00:14:24,259 --> 00:14:28,259
به دوره جبر خطی من ی نگاه بندازید - مخصوصا فصل 3 اش

192
00:14:28,918 --> 00:14:34,918
بجای این که عدد مبنا رو به این مقدار ها دونه دونه اضافه کنیم

193
00:14:34,888 --> 00:14:42,388
اونا رو به صورت ی بردار نمایش میدیم و اون رو با حاصل ضرب ماتریسی قبلی جمع میکنیم

194
00:14:42,672 --> 00:14:47,672
و در آخر اونا رو میزاریم توی تابع سیگموید

195
00:14:47,917 --> 00:14:54,917
و این کار مثل این میمونه که تابع سیگموید رو روی تک تک اعضای ماتریس حاصل اعمال کنید

196
00:14:55,591 --> 00:15:00,567
اگر ماتریس وزن ها و بردار هارو به صورت نمادشون بنویسیم

197
00:15:00,567 --> 00:15:08,067
میتونی مقدار عددهای فعالسازی رو توی ی عبارت کوچیک نشون بدی

198
00:15:08,171 --> 00:15:12,118
این کار نوشتن کد(برنامه کامپیوتری) اش رو خیلی ساده تر و سریع تر میکنه

199
00:15:12,118 --> 00:15:15,980
از اونجایی که خیلی از کتابخونه ها، ضرب های ماتریسی پیچیده رو به صورت بهینه انجام میدن

200
00:15:17,128 --> 00:15:22,003
یادته که گفتم عصب به طور ساده، ی چیزیه که عدد داره؟

201
00:15:22,115 --> 00:15:26,754
اینم باید اضافه کنم که عددی که میگیرن بستگی داره به اینکه چه عکسی به عنوان ورودی بهش بدی

202
00:15:27,774 --> 00:15:31,778
پس بهتره هر عصب رو مثل ی تابع در نظر بگیری

203
00:15:31,778 --> 00:15:35,831
تابعی که مقدار عصب های لایه قبل رو میگیره

204
00:15:35,831 --> 00:15:38,941
و ی عدد بین 0 تا 1 خروجی میده

205
00:15:39,173 --> 00:15:41,317
درواقع، کل شبکه مثل ی تابع میمونه

206
00:15:41,317 --> 00:15:47,402
تابعی که 784 تا پیکسل رو به عنوان ورودی میگیره و در آخر 10 تا عدد خروجی میده

207
00:15:47,402 --> 00:15:53,812
ی تابع خیلی پیچیده است از اونجایی که سیزده هزار متغیر داره که به شکل وزن ها و عدد های مبنا هستن

208
00:15:53,812 --> 00:15:55,759
که هر کدوم الگو های خاصی رو مشخص میکنن

209
00:15:55,759 --> 00:16:00,571
که نیازه تا کلی عملیات ماتریسی با کمک تابع سیگموید انجام بشه

210
00:16:00,850 --> 00:16:03,557
ولی به هرحال ی تابع به حساب میاد

211
00:16:03,557 --> 00:16:06,835
با این اوضاع، مطمئنا تابع پیچیده ایه

212
00:16:06,835 --> 00:16:12,844
اگر راه ساده تری وجود داشت، چ انگیزه ای برای تشخیص عدد توسط کامپیوتر داشتیم؟

213
00:16:12,820 --> 00:16:14,966
و کامپیوتر چطور این کار چالشی رو انجام میده؟

214
00:16:14,966 --> 00:16:19,589
چطوری کامپیوتر این همه وزن و عدد مبنا رو فقط از طریق داده هایی که بهش میدیم پیدا میکنه؟

215
00:16:19,589 --> 00:16:21,846
خب اینو توی قسمت بعدی بهتون میگم

216
00:16:21,846 --> 00:16:26,711
و بهتون میگم که این شبکه دقیقا چیکار میکنه

217
00:16:26,711 --> 00:16:33,211
الان موقع خوبیه که بهتون بگم مارو دنبال کنید تا هروقت که ویدیو جدید اومد مطلع بشید

218
00:16:33,269 --> 00:16:37,269
ولی بیشتر شما از یوتیوب اعلان دریافت نمیکنید، مگه نه؟

219
00:16:37,466 --> 00:16:45,096
شاید بهتره بگم مارو دنبال کن تا شبکه مصنوعی که پشت سیستم پیشنهاد ویدئوی یوتیوب هست مطمئن بشن

220
00:16:45,096 --> 00:16:48,339
که میخوای مطالب و ویدیو های این کانال بهت پیشنهاد داده بشه

221
00:16:48,339 --> 00:16:50,339
به هرحال در جریان مطالب جدید باشید :D

222
00:16:50,533 --> 00:16:53,908
داره از کسایی که کمک مالی اش کردن تشکر میکنه

223
00:16:54,076 --> 00:17:02,076
...

224
00:17:03,445 --> 00:17:12,352
در انتها، از خانم "لیشا لی" که پایان نامه دکترا اش رو در رابطه با بخش تئوری "یادگیری عمیق" انجام داده و توی .... کار میکنه

225
00:17:12,352 --> 00:17:15,394
همونجایی که برای درست کردن این ویدئو بهم کمک مالی کردن، دعوت میکنم

226
00:17:15,394 --> 00:17:19,192
خب "لیشا" به نظرم بهتره مطرح کنیم، تابع سیگموید عه

227
00:17:19,192 --> 00:17:24,970
اونطوری که من فهمیدم، شبکه های عصبی اولیه از این تابع استفاده میکردن تا جمع وزن دار رو به ی چیزی بین 0 و 1 تبدیل کنن

228
00:17:24,970 --> 00:17:29,383
و این ی جورایی که زیست شناسی الهام گرفته شده که عصب ها فعال بشن یا نه

229
00:17:29,383 --> 00:17:30,194
- دقیقا

230
00:17:30,194 --> 00:17:35,769
ولی تعداد کمی از شبکه های عصبی جدید از این تابع استفاده میکنن و ی جورایی قدیمیه - درسته؟

231
00:17:35,769 --> 00:17:39,029
اره درسته. یا اینکه تابع "رلیو" به ساده تر به نظر میرسید برای تمرین دادن شبکه

232
00:17:39,029 --> 00:17:42,471
ReLU => Rectified Linear Unit

233
00:17:42,509 --> 00:17:49,438
اره - ی تابعیه که بیشترین مقدار بین 0 و ورودی اش رو محاسبه میکنه

234
00:17:49,438 --> 00:17:57,438
همونطوری که توی این ویدئو توضیح دادی، این تابع ی جورایی از زیست شناسی الهام گرفته شده

235
00:17:57,428 --> 00:18:05,785
که عصب ها فعال بشن یا نشن - اگر از ی حدی بگذره میشه تابع همانی

236
00:18:05,785 --> 00:18:09,643
ولی اگر از اون حد کمتر باشه، اون عصب فعال نمیشه یعنی برابر با 0 میشه

237
00:18:09,643 --> 00:18:11,192
که ی جورایی ساده تر میکنه کارو

238
00:18:11,192 --> 00:18:15,806
تابع سیگموید به تمرین دادن شبکه کمکی نکرد یا خیلی کار رو سخت میکرد بعضی مواقع

239
00:18:15,806 --> 00:18:24,708
بخاطر این اومدن از تابع "ریلو" استفاده کردن و با وجود شبکه های خیلی عمیق عصبی هم خوب عمل کرد

240
00:18:24,708 --> 00:18:26,114
ممنون از شما خانم لیشا

241
00:18:26,114 --> 00:18:35,056
داره میگه این شرکتی که این خانمه توش کار میکنه، روی شرکت های هوش مصنوعی سرمایه گذاری میکنه

242
00:18:35,056 --> 00:18:51,421
تبلیغشو میکنه

243
00:18:52,038 --> 00:19:12,538
ترجمه شدن توسط انجمن علمی مهندسی کامپیوتر دانشگاه شاهد - بهمن 1400